# Note 19 - Mar 21

# 6. Continuous-Time Markov Chain (cont'd)

## 6.1. Definitions and Structures (cont'd)

### Definition 6.1.1. Continuous-time Stochastic Process (cont'd)

#### Example 6.1.1.1.

We have seen that the Poisson process satisfy the continuous-time Markov property $\Rightarrow$ it is a CTMC

$$ \lambda_i=\lambda \quad\quad i\in S=\{0,1,2,\cdots\} $$

\(interarrival times do not depend on current state. $\Rightarrow$ time spent in different states are i.i.d.)

$$ q_{i,i+i} = 1\quad\quad q_{ij} = 0 \text{ otherwise}(j\cancel{=}i+1) $$

## 6.2. Generator Matrix

Similar to the discrete-time case, we have the transition probability at time $t$.

$$ \begin{aligned}
    P_{ij}(t)
        &= \mathbb{P}(X(t)=j|X(0)=i)  \\
        &= \mathbb{P}(X(t+s)=j|X(s)=i)  \quad\quad\text{assume the MC is time-homogeneous}
\end{aligned} $$

and matrix

$$ P(t)=\{P_{ij}(t)\}_{i,j\in S}$$

$$ P(t)=\begin{pmatrix}
    p_{00}(t) & p_{01}(t) & \cdots  \\
    p_{10}(t) & p_{11}(t) & \cdots  \\
    \vdots & \vdots &
\end{pmatrix} $$

The C-K equation still holds
$$ p(t+s) = P(t)\cdot P(s)$$

__Proof__: $\forall i,j\in S$

$$ \begin{aligned}
P_{ij}(t+s)
    &= \mathbb{P}(X(t+s)=j|X(0)=i) \\
    &= \sum_{k\in S}\mathbb{P}(X(t+s)=j|X(t)=k,\cancel{X(0)=i})\cdot \mathbb{P}(X(t)=k|X(0)=i)  \\
    &= \sum_{k\in S}\mathbb{P}(X(s)+j|X(o)=k)\cdot\mathbb{P}(X(t)=k|X(0)=i) \\
    &= \sum_{k\in S}P_{kj}(s)\cdot P_{ik}(t)\\
    &=(P(t)\cdot P(s))_{ij}\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\blacksquare
\end{aligned}$$

Note that we have 
$$ P(0) = I $$
$$ (P_{ii}(0)=\mathbb{P}(X(0)=i|X(0)=i) = 1, P_{ij}(0)=0\text{ for } j\cancel{=}i)$$
and
$$ \lim_{t\rightarrow0^+} P(t)=I $$

Actually, we have the following stronger result:
$$ R:= \lim_{h\rightarrow 0^+}\frac{P(h)-P(0)}{h}=\lim_{h\rightarrow0^+}\frac{P(h)-I}{h} $$
exists, and is called the __(infinitesimal) _generator_ matrix of $\{X(t)\}_{t\geq 0}$__

Entry-wise:
$$ R_{ij}=\lim_{h\rightarrow0^+}\frac{P_{ij}(h)-P_{ij}(0)}{h} = \begin{cases}
    \lim_{h\rightarrow0^+}\frac{P_{ii}(n)-1}{h}\leq 0\quad  j = i\\
    \lim_{h\rightarrow0^+}\frac{P_{ii}(n)}{h}\geq 0\quad\quad j \cancel{=}i
\end{cases} $$

Relation between $R$ and $\{\lambda_i\}_{i\in S}$ and $Q=\{q_{ij}\}_{i,j\in S}$
$$ R_{ii}=-\lambda_i\quad,\quad R_{ij}=\lambda_iq_{ij}\quad\quad j\cancel{=}i$$

__Reason__:

$$ \begin{aligned}
R_{ii}=\lim_{h\rightarrow0^+}\frac{P_{ii}(h)-1}{h} = \lim_{h\rightarrow0^+}\frac{\mathbb{P}(T_i>h) - 1}{h}
\end{aligned} $$

Where $T_i$ is the random time the process stays in $i$. The equality holds because when $h$ is very small, the probability of having two or more jumps in time $h$ is negligible.

$$ \mathbb{P}(X(h)=i|X(0)=i) = \mathbb{P}(T_i>h) +o(h)\leftarrow\text{having at least 2 jumps and back to $i$} $$
$$ * a(h)=o(h) \text{ if } \lim_{h\rightarrow 0}\frac{a(h)}{h}=0 $$